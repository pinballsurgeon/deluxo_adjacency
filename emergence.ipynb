{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pinballsurgeon/sweeping_analysis/blob/main/emergence.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9dJdg4LTLDY"
      },
      "source": [
        "## installs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6G8PF6dZ36hP",
        "outputId": "db61abd9-7d85-49bd-bf4f-23fcadd47f45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytrends\n",
            "  Downloading pytrends-4.8.0.tar.gz (19 kB)\n",
            "Requirement already satisfied: requests>=2.0 in /usr/local/lib/python3.7/dist-packages (from pytrends) (2.23.0)\n",
            "Requirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.7/dist-packages (from pytrends) (1.3.5)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from pytrends) (4.2.6)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25->pytrends) (1.21.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25->pytrends) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25->pytrends) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.25->pytrends) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0->pytrends) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0->pytrends) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0->pytrends) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0->pytrends) (1.24.3)\n",
            "Building wheels for collected packages: pytrends\n",
            "  Building wheel for pytrends (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytrends: filename=pytrends-4.8.0-py3-none-any.whl size=16126 sha256=55f17ec3f97e1eac274a13c68303d973a53113eca8b72ac1b68339e5066de19e\n",
            "  Stored in directory: /root/.cache/pip/wheels/07/6f/5c/8174f98dec1bfbc7d5da4092854afcbcff4b26c3d9b66b5183\n",
            "Successfully built pytrends\n",
            "Installing collected packages: pytrends\n",
            "Successfully installed pytrends-4.8.0\n",
            "Collecting joypy\n",
            "  Downloading joypy-0.2.6-py2.py3-none-any.whl (8.6 kB)\n",
            "Requirement already satisfied: pandas>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from joypy) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from joypy) (1.21.5)\n",
            "Requirement already satisfied: scipy>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from joypy) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from joypy) (3.2.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.20.0->joypy) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.20.0->joypy) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.20.0->joypy) (1.15.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->joypy) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->joypy) (3.0.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->joypy) (1.3.2)\n",
            "Installing collected packages: joypy\n",
            "Successfully installed joypy-0.2.6\n",
            "Collecting openai\n",
            "  Downloading openai-0.15.0.tar.gz (40 kB)\n",
            "\u001b[K     |████████████████████████████████| 40 kB 3.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.7/dist-packages (from openai) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from openai) (4.63.0)\n",
            "Requirement already satisfied: pandas>=1.2.3 in /usr/local/lib/python3.7/dist-packages (from openai) (1.3.5)\n",
            "Collecting pandas-stubs>=1.1.0.11\n",
            "  Downloading pandas_stubs-1.2.0.49-py3-none-any.whl (161 kB)\n",
            "\u001b[K     |████████████████████████████████| 161 kB 5.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: openpyxl>=3.0.7 in /usr/local/lib/python3.7/dist-packages (from openai) (3.0.9)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.7/dist-packages (from openpyxl>=3.0.7->openai) (1.1.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.3->openai) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.3->openai) (1.21.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.3->openai) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from pandas-stubs>=1.1.0.11->openai) (3.10.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.3->openai) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (3.0.4)\n",
            "Building wheels for collected packages: openai\n",
            "  Building wheel for openai (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai: filename=openai-0.15.0-py3-none-any.whl size=50093 sha256=af798e8894649ac8ea8f81045ede530606886d6cd9ef9e337fc5d8f804144096\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/b1/b5/01a94056fd87ef0ed913b2fa6f1161076b730cf1449f579ab7\n",
            "Successfully built openai\n",
            "Installing collected packages: pandas-stubs, openai\n",
            "Successfully installed openai-0.15.0 pandas-stubs-1.2.0.49\n"
          ]
        }
      ],
      "source": [
        "!pip install pytrends\n",
        "!pip install joypy\n",
        "\n",
        "# install openai\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWG_yZP1TJGo"
      },
      "source": [
        "## imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GaUejYHj0rAZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "aeddf184-f7c6-4a5a-bf4a-cc1d92c26d39"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-8736f6b352ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# supply openai api key via file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mopenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'openai_key'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'openai_key'"
          ]
        }
      ],
      "source": [
        "import numpy\n",
        "import pandas \n",
        "import re\n",
        "import string\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "from pytrends.request import TrendReq\n",
        "from pytrends         import dailydata\n",
        "import pytrends\n",
        "from operator         import index\n",
        "\n",
        "import joypy\n",
        "from matplotlib import cm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn \n",
        "\n",
        "import openai\n",
        "\n",
        "import networkx as nx\n",
        "\n",
        "# supply openai api key via file \n",
        "openai.api_key = open('openai_key').read()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpJhiDNngony"
      },
      "source": [
        "## seed config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6fBrXn4KLZXI"
      },
      "outputs": [],
      "source": [
        "# connection strenth minimum boost, base on standard deviation\n",
        "std_factor = .6\n",
        "\n",
        "\n",
        "# seed topics\n",
        "topics = ['asthma', 'bronchitis', 'sinusitis'\n",
        "        , 'hypertension', 'pharmacy', 'primary care', 'bruise', 'sprain', 'strain', 'exczema', 'cellulitis', 'abscesses', 'strep throat'\n",
        "        , 'ear infection', 'diabetes', 'migranes', 'pink eye', 'bladder infection', 'attention deficit', 'depression', 'anxiety']\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## helper functions\n",
        "  1. get_trend_frame(topics, years): returns a dataframe of topic trends\n",
        "  2. stack_nodes_vertically(df_features):\n",
        "  3. build_node_labels(df_flat):"
      ],
      "metadata": {
        "id": "hpZqpTQgKIQz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bRHT-HAW4iLc"
      },
      "outputs": [],
      "source": [
        "### 1. for a given list of topics, return dataframe of interests from pytrend\n",
        "def get_trend_frame(topics, years):\n",
        "\n",
        "  # initialize return frame\n",
        "  df_total = pandas.DataFrame()\n",
        "\n",
        "  # for each provided \n",
        "  for topic in topics:\n",
        "\n",
        "    # pytrend request\n",
        "    pytrend = TrendReq()\n",
        "    pytrend.build_payload(kw_list=[topic]\n",
        "                         ,timeframe=( 'today %s-y' % (years)))\n",
        "    \n",
        "    # load trend request\n",
        "    df = pytrend.interest_over_time()\n",
        "\n",
        "    # add column for new topic\n",
        "    df_total[topic] = df[topic]\n",
        "\n",
        "  # drop nans\n",
        "  df_total = df_total.dropna()\n",
        "\n",
        "  # return standard frame\n",
        "  return df_total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nuy8_7_9jk6K"
      },
      "outputs": [],
      "source": [
        "### 2. for each topic and interval of time, stack a vertical dataframe of value counts\n",
        "def stack_nodes_vertically(df_features):\n",
        "\n",
        "  # initialize buffers resources\n",
        "  df_stk=pandas.DataFrame()\n",
        "  globalst=[]\n",
        "\n",
        "  # for each feature\n",
        "  for col in df_features:                      # topic\n",
        "\n",
        "      # for each time interval\n",
        "      for val in df_features.index.weekofyear: # weeknum\n",
        "\n",
        "          # time sensitive\n",
        "          fs_val = df_features[col][val]       # full spectrum\n",
        "          \n",
        "          # iterate through each instance of max bin occurence, determining number of weeks written\n",
        "          for x in range(0,int(abs(fs_val) * 100)):\n",
        "          \n",
        "              # build buffer list\n",
        "              lst = [val, val, col]\n",
        "              globalst.append(lst)\n",
        "\n",
        "  # materialize vertically flattened\n",
        "  df_flat = pandas.DataFrame(globalst\n",
        "                            ,columns=['WeekNum'\n",
        "                            ,'WeekNum_Rct'\n",
        "                            ,'Flower_Tot'])\n",
        "  \n",
        "  return df_flat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_lbF2IB4icN"
      },
      "outputs": [],
      "source": [
        "### 3. prefix ridgemap/joyplot labels with weeknum average\n",
        "def build_node_labels(df_flat):\n",
        "  \n",
        "  # get all distinct nodes\n",
        "  df_stats = df_flat.groupby('Flower_Tot').agg(['mean', 'count']).reset_index()\n",
        "\n",
        "  # rename columns to node labels\n",
        "  df_stats.columns = [' '.join(col).strip() for col in df_stats.columns.values]\n",
        "\n",
        "  # sort by average time interval\n",
        "  df_stats = df_stats.sort_values(by='WeekNum mean',ascending=True)\n",
        "\n",
        "  # include average into node label\n",
        "  df_stats['Name'] = ( ( df_stats['WeekNum mean'] * 100) + 1000).astype('int').astype('str') + ' '+ df_stats['Flower_Tot']\n",
        "\n",
        "  # update flattened node space with averaged names\n",
        "  for index, row in df_stats.iterrows():\n",
        "      df_flat['Flower_Tot'] = df_flat['Flower_Tot'].replace(row['Flower_Tot'], row['Name'])\n",
        "\n",
        "  return df_flat"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### 4. display ridgeplot of time frame, for \n",
        "def get_ridgeplot(df_flat):\n",
        "\n",
        "  # configure and build ridgeplot\n",
        "  fig, axes = joypy.joyplot(df_flat\n",
        "                            , column=['WeekNum', 'WeekNum_Rct']\n",
        "                            , by='Flower_Tot'\n",
        "                            , overlap=1.2\n",
        "                            , fill=True\n",
        "                            , figsize=(22,12)\n",
        "                            , x_range = [0,52]\n",
        "                            , colormap=cm.cool                         \n",
        "                            , ylim='own'\n",
        "                          )\n",
        "\n",
        "  # write ridgeplot\n",
        "  plt.savefig('frank_jj.png')\n",
        "\n",
        "  # plot\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "SnZfekidR963"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 5. send openai question, receive response\n",
        "def get_openai_response(question):\n",
        "\n",
        "    # format open au request\n",
        "    response = openai.Completion.create(\n",
        "                      engine=\"text-davinci-001\",\n",
        "                      prompt=question,\n",
        "                      temperature=.01,\n",
        "                      max_tokens=250,\n",
        "                      top_p=1,\n",
        "                      frequency_penalty=50,\n",
        "                      presence_penalty=0 )\n",
        "\n",
        "    # parse and process open ai response\n",
        "    response_choices = response[\"choices\"]\n",
        "\n",
        "    # replace blanks\n",
        "    response = response_choices[0][\"text\"].strip('\\n')\n",
        "\n",
        "    return response"
      ],
      "metadata": {
        "id": "l1Q4o58dQg9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fVOt05VmdEjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FuUG92OfdE0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def swap_tokens(topics, chk_topics, new_topics):\n",
        "\n",
        "  buffer_lst = []\n",
        "\n",
        "\n",
        "  # for each full list of topics\n",
        "  for topic in topics:\n",
        "\n",
        "    # for each graphed topics\n",
        "    for chk_topic in chk_topics:\n",
        "\n",
        "      # if \n",
        "      if topic == chk_topic:\n",
        "\n",
        "        buffer_lst.append(topic)\n",
        "\n",
        "\n",
        "  for new_topic in new_topics:\n",
        "    buffer_lst.append(new_topic)\n",
        "\n",
        "\n",
        "  return buffer_lst\n"
      ],
      "metadata": {
        "id": "Iko3rJCLdFG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "igEaX81ifwCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pairwise_similarity(df_features, topics, std_factor):\n",
        "\n",
        "  # pair wise correlation / similarity\n",
        "  c = df_features.corr().abs()\n",
        "\n",
        "  # flatten and sort\n",
        "  so = c.unstack().sort_values(kind=\"quicksort\")\n",
        "\n",
        "  # remove low connections\n",
        "  min_connection_strength = so.mean() + ( std_factor * so.std() )\n",
        "  min_connection_cutoff = len(so) - len(so[so > min_connection_strength])\n",
        "\n",
        "  # turn to frame\n",
        "  df_slice = so[min_connection_cutoff:-len(topics)].to_frame()\n",
        "\n",
        "  df_slice.reset_index(inplace=True)\n",
        "\n",
        "  df_slice.columns = ['source','target','weight']\n",
        "\n",
        "  return df_slice\n",
        "\n",
        "  #df_slice.hist()"
      ],
      "metadata": {
        "id": "cLyLhzvffwTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_graph_network(df_slice):\n",
        "\n",
        "  # build graph \n",
        "  G = nx.from_pandas_edgelist(df_slice\n",
        "                            ,'source'          # parent\n",
        "                            ,'target'          # child\n",
        "                            , ['weight'])      # relationship\n",
        "\n",
        "\n",
        "  # define plot area\n",
        "  plt.figure(3,figsize=(12,12)) \n",
        "\n",
        "\n",
        "  # visualize graph \n",
        "  nx.draw(G                        \n",
        "      ,with_labels=True\n",
        "      ,edge_color='gray'\n",
        "      ,node_color='white'\n",
        "      ,font_size=22)\n",
        "  \n",
        "  return G"
      ],
      "metadata": {
        "id": "AICJ2mO_h5dd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_openai_generated_topics(topic):\n",
        "  responses = []\n",
        "\n",
        "  # retrieve \n",
        "  retrieval = get_openai_response('list objects related to %s' % (topic))\n",
        "  responses.append(retrieval)\n",
        "\n",
        "  new_tokens = re.split(\"; |, |\\*|\\n\",responses[0].lower())\n",
        "\n",
        "  return new_tokens"
      ],
      "metadata": {
        "id": "Ski7o9Ezh5so"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ce29Glkzh6C0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## gather, pre-process and stage graph data structure"
      ],
      "metadata": {
        "id": "esEyoi87K8fd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utiv9ScViQTb"
      },
      "outputs": [],
      "source": [
        "# request features\n",
        "df_features = get_trend_frame(topics, '5')[topics]\n",
        "\n",
        "# normalize feature space\n",
        "df_features=(df_features-df_features.mean())/df_features.std()\n",
        "\n",
        "# flatten feature space vertically\n",
        "df_flat = stack_nodes_vertically(df_features)\n",
        "\n",
        "# build node labels\n",
        "df_flat = build_node_labels(df_flat)\n",
        "\n",
        "# display ridgeplot of events\n",
        "get_ridgeplot(df_flat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GwI-_CfpTFjk"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9K_zNAkMrXv"
      },
      "outputs": [],
      "source": [
        "# time-based pairwise similiarity weights\n",
        "df_slice = get_pairwise_similarity(df_features, topics, std_factor)\n",
        "\n",
        "# display flattened histogram\n",
        "df_slice.hist()\n",
        "\n",
        "# build graph\n",
        "G = build_graph_network(df_slice)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLhuMw06acSo"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RwVqHIVRaduM"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dC9iB8QXCyWY"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZIQvoHMOkl4"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAKCkgXrCy2L"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eWHPfa5XF8cc"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lulhg1UoH_J8"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdxuGicoF8w3"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DK75ZXw7Cy_8"
      },
      "outputs": [],
      "source": [
        "### graph properties\n",
        "\n",
        "# list nodes\n",
        "G.nodes.items()\n",
        "\n",
        "# number of edges in graph\n",
        "G.number_of_edges()\n",
        "\n",
        "# number of nodes in graph\n",
        "G.number_of_nodes()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRilHrwycAEt"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpIi6Xt2cA0E"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cl2gqeBfcBDZ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6sq55saRcSkd"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0Rn5Mkicdur"
      },
      "outputs": [],
      "source": [
        "lst_buffer = []\n",
        "graph_topics = list(df_slice['source'].unique())\n",
        "\n",
        "for graph_topic in graph_topics:\n",
        "  topic_list = get_openai_generated_topics(graph_topic)\n",
        "\n",
        "  for topic in topic_list:\n",
        "\n",
        "    if len(topic) < 10 and len(topic) > 2:\n",
        "\n",
        "      topic = topic.translate(string.punctuation)\n",
        "      topic = re.sub(r'[^\\w\\s]','',topic)\n",
        "      lst_buffer.append(topic)\n",
        "  \n",
        "  print(lst_buffer)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lst_buffer.append('the fireworks')"
      ],
      "metadata": {
        "id": "Z3uXA2MYZPC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reduce_similiar_topics(lst_ref, lst_new)):\n",
        "  \n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "  print('%s vs %s' % (lst_buffer[4], lst_buffer[8]))\n",
        "  SequenceMatcher(None, lst_buffer[4], lst_buffer[8]).ratio()"
      ],
      "metadata": {
        "id": "OQQWXlMhZPWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chk_topics = list(df_slice['source'].unique())"
      ],
      "metadata": {
        "id": "hQiUbkliZPmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-tTNwurEa4iZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "swap_tokens(topics, chk_topics, new_tokens)"
      ],
      "metadata": {
        "id": "DlsBkDV2a4wD"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "j9dJdg4LTLDY",
        "zWG_yZP1TJGo"
      ],
      "name": "emergence.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNb78Oz6lLc3ZorJzsQ3+X9",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}