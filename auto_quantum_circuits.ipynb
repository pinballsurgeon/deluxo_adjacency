{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "auto_quantum_circuits.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM64t/LGdiKCgx4x/R6G2Rm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pinballsurgeon/deluxo_adjacency/blob/main/auto_quantum_circuits.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Auto Quantum Circuits\n",
        "#### dehls - pinballsurgeon@gmail.com"
      ],
      "metadata": {
        "id": "dhwB9OhHwgvh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "kL3NaosJFyiz"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet tensorflow_quantum"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "EgOLMHAQwd-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cirq\n",
        "import sympy\n",
        "import tensorflow\n",
        "import numpy\n",
        "import gc\n",
        "\n",
        "%matplotlib inline\n",
        "from matplotlib import pyplot\n",
        "\n",
        "from cirq.contrib.svg import SVGCircuit\n",
        "\n",
        "import tensorflow_quantum"
      ],
      "metadata": {
        "id": "DUlhaeoeGPop"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Helper Functions"
      ],
      "metadata": {
        "id": "TJlbByAk3buT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# given a data and out qubit structure, build dynamic circuit\n",
        "class circuit_struct():\n",
        "    def __init__(self, data_qubits, readout):\n",
        "        self.data_qubits = data_qubits\n",
        "        self.readout = readout\n",
        "    \n",
        "    def add_layer(self, circuit, gate, prefix):\n",
        "        for i, qubit in enumerate(self.data_qubits):\n",
        "            symbol = sympy.Symbol(prefix + '-' + str(i))\n",
        "            circuit.append(gate(qubit, self.readout)**symbol)"
      ],
      "metadata": {
        "id": "nvcBT4RIGP3Y"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# given a combination of qubit grid size and gate population, build \n",
        "def create_quantum_model(gridSize, hyperGates):\n",
        "\n",
        "    # cirq\n",
        "    data_qubits = cirq.GridQubit.rect(gridSize, gridSize)\n",
        "    readout = cirq.GridQubit(-1, -1)         \n",
        "    circuit = cirq.Circuit()\n",
        "    \n",
        "    # prepare the readout qubit\n",
        "    circuit.append(cirq.X(readout))\n",
        "    circuit.append(cirq.H(readout))\n",
        "    \n",
        "    # create qubit\n",
        "    builder = circuit_struct(\n",
        "        data_qubits = data_qubits,\n",
        "        readout=readout)\n",
        "\n",
        "    # buid layers\n",
        "    for gate in hyperGates:\n",
        "\n",
        "      # builder.add_layer(circuit, cirq.XX, \"xx1\")\n",
        "      builder.add_layer(circuit, gate, \"zz1\")\n",
        "   \n",
        "    # prepare the readout qubit\n",
        "    circuit.append(cirq.H(readout))\n",
        "\n",
        "    return circuit, cirq.Z(readout)"
      ],
      "metadata": {
        "id": "c_eitDLdGQE5"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### pixel to qubit\n",
        "def convert_to_circuit(image):\n",
        "\n",
        "    values = numpy.ndarray.flatten(image)\n",
        "    qubits = cirq.GridQubit.rect(4, 4)\n",
        "    circuit = cirq.Circuit()\n",
        "    for i, value in enumerate(values):\n",
        "        if value:\n",
        "            circuit.append(cirq.X(qubits[i]))\n",
        "    return circuit"
      ],
      "metadata": {
        "id": "ISAOn5Aa-CXb"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = tensorflow.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Rescale the images from [0,255] to the [0.0,1.0] range.\n",
        "x_train, x_test = x_train[..., numpy.newaxis]/255.0, x_test[..., numpy.newaxis]/255.0"
      ],
      "metadata": {
        "id": "vHHqySURQyHH"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_36(x, y):\n",
        "    keep = (y == 3) | (y == 6)\n",
        "    x, y = x[keep], y[keep]\n",
        "    y = y == 3\n",
        "    return x,y"
      ],
      "metadata": {
        "id": "9xwbMDuyQ1-3"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train = filter_36(x_train, y_train)\n",
        "x_test, y_test = filter_36(x_test, y_test)"
      ],
      "metadata": {
        "id": "j_4RnsIcRAEy"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_small = tensorflow.image.resize(x_train, (4,4)).numpy()\n",
        "x_test_small = tensorflow.image.resize(x_test, (4,4)).numpy()"
      ],
      "metadata": {
        "id": "uI8h9oL_RASH"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_nocon, y_train_nocon = x_train_small[:100], y_train[:100]"
      ],
      "metadata": {
        "id": "FgX1VGpkRAcN"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_circ = [convert_to_circuit(x) for x in x_train_nocon]\n",
        "x_test_circ = [convert_to_circuit(x) for x in x_test_small]"
      ],
      "metadata": {
        "id": "76AtlTfERWMs"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_tfcirc = tensorflow_quantum.convert_to_tensor(x_train_circ)\n",
        "x_test_tfcirc = tensorflow_quantum.convert_to_tensor(x_test_circ)"
      ],
      "metadata": {
        "id": "TtA0FZ5WRWZe"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 25\n",
        "BATCH_SIZE = 25\n",
        "\n",
        "NUM_EXAMPLES = len(x_train_tfcirc)"
      ],
      "metadata": {
        "id": "sGUGGqDdRsDv"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_tfcirc_sub = x_train_tfcirc[:NUM_EXAMPLES]\n",
        "y_train_hinge_sub = y_train_nocon[:NUM_EXAMPLES]"
      ],
      "metadata": {
        "id": "uUvyxpKqRsLJ"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class mem_release(tensorflow.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        gc.collect()"
      ],
      "metadata": {
        "id": "UsvRncZpRsSN"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "experiment_count = 0\n",
        "experiment_log = {}\n",
        "for gates in [[cirq.CNOT, cirq.XX], [cirq.XX, cirq.ISWAP], [cirq.SWAP, cirq.XX], [cirq.CZ, cirq.ZZ], [cirq.ZZ, cirq.YY]]:\n",
        "  for gridSize_int in [2, 3]:\n",
        "\n",
        "    model_circuit, model_readout = create_quantum_model(gridSize_int, gates)\n",
        "    \n",
        "    # Build the Keras model.\n",
        "    model = tensorflow.keras.Sequential([\n",
        "        # The input is the data-circuit, encoded as a tf.string\n",
        "        tensorflow.keras.layers.Input(shape=(), dtype=tensorflow.string),\n",
        "        # tensorflow.keras.layers.Dense(64, activation='relu'),\n",
        "        # The PQC layer returns the expected value of the readout gate, range [-1,1].\n",
        "        tensorflow_quantum.layers.PQC(model_circuit, model_readout),])\n",
        "\n",
        "    model.compile(\n",
        "      loss=tensorflow.keras.losses.mse,\n",
        "      optimizer=tensorflow.keras.optimizers.Adam(),\n",
        "      metrics=[tensorflow.keras.metrics.BinaryAccuracy()]\n",
        "      )\n",
        "    \n",
        "    print(model.summary())\n",
        "\n",
        "    qnn_history = model.fit(\n",
        "        x_train_tfcirc_sub, y_train_hinge_sub,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        epochs=EPOCHS,\n",
        "        verbose=1,\n",
        "        callbacks=[mem_release()],\n",
        "        validation_data=(x_test_tfcirc, y_test)\n",
        "        )\n",
        "\n",
        "    qnn_results = model.evaluate(x_test_tfcirc, y_test)\n",
        "\n",
        "    experiment_count += 1\n",
        "    experiment_log[experiment_count] = {'circuit' : model_circuit\n",
        "                                       ,'gates'   : gates\n",
        "                                       ,'history' : qnn_history}\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPcJoEuGGgoN",
        "outputId": "c86ab60c-f2a6-4ab4-d961-ca71acd1ed40"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_90\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " pqc_90 (PQC)                (None, 1)                 4         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4\n",
            "Trainable params: 4\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/25\n",
            "4/4 [==============================] - 2s 441ms/step - loss: 1.6000 - binary_accuracy: 0.5600 - val_loss: 1.5478 - val_binary_accuracy: 0.4959\n",
            "Epoch 2/25\n",
            "4/4 [==============================] - 2s 529ms/step - loss: 1.4400 - binary_accuracy: 0.6100 - val_loss: 1.5478 - val_binary_accuracy: 0.4959\n",
            "Epoch 3/25\n",
            "4/4 [==============================] - 2s 648ms/step - loss: 1.6400 - binary_accuracy: 0.5700 - val_loss: 1.5478 - val_binary_accuracy: 0.4959\n",
            "Epoch 4/25\n",
            "4/4 [==============================] - 2s 656ms/step - loss: 1.4800 - binary_accuracy: 0.5900 - val_loss: 1.5478 - val_binary_accuracy: 0.4959\n",
            "Epoch 5/25\n",
            "4/4 [==============================] - 2s 746ms/step - loss: 1.3600 - binary_accuracy: 0.6000 - val_loss: 1.5478 - val_binary_accuracy: 0.4959\n",
            "Epoch 6/25\n",
            "4/4 [==============================] - 2s 690ms/step - loss: 1.6800 - binary_accuracy: 0.5400 - val_loss: 1.5478 - val_binary_accuracy: 0.4959\n",
            "Epoch 7/25\n",
            "4/4 [==============================] - 2s 806ms/step - loss: 1.6400 - binary_accuracy: 0.6000 - val_loss: 1.5478 - val_binary_accuracy: 0.4959\n",
            "Epoch 8/25\n",
            "4/4 [==============================] - 3s 891ms/step - loss: 1.3600 - binary_accuracy: 0.6300 - val_loss: 1.5478 - val_binary_accuracy: 0.4959\n",
            "Epoch 9/25\n",
            "4/4 [==============================] - 2s 744ms/step - loss: 1.4000 - binary_accuracy: 0.5700 - val_loss: 1.5478 - val_binary_accuracy: 0.4959\n",
            "Epoch 10/25\n",
            "4/4 [==============================] - 2s 731ms/step - loss: 1.6400 - binary_accuracy: 0.5800 - val_loss: 1.5478 - val_binary_accuracy: 0.4959\n",
            "Epoch 11/25\n",
            "4/4 [==============================] - 2s 732ms/step - loss: 1.6000 - binary_accuracy: 0.5600 - val_loss: 1.5478 - val_binary_accuracy: 0.4959\n",
            "Epoch 12/25\n",
            "4/4 [==============================] - 2s 653ms/step - loss: 1.4000 - binary_accuracy: 0.5800 - val_loss: 1.5478 - val_binary_accuracy: 0.4959\n",
            "Epoch 13/25\n",
            "4/4 [==============================] - 2s 753ms/step - loss: 1.5200 - binary_accuracy: 0.5400 - val_loss: 1.5478 - val_binary_accuracy: 0.4959\n",
            "Epoch 14/25\n",
            "4/4 [==============================] - 2s 665ms/step - loss: 1.3200 - binary_accuracy: 0.6300 - val_loss: 1.5478 - val_binary_accuracy: 0.4959\n",
            "Epoch 15/25\n",
            "4/4 [==============================] - 2s 705ms/step - loss: 1.7200 - binary_accuracy: 0.5200 - val_loss: 1.5478 - val_binary_accuracy: 0.4959\n",
            "Epoch 16/25\n",
            "4/4 [==============================] - 2s 654ms/step - loss: 1.7200 - binary_accuracy: 0.5500 - val_loss: 1.5478 - val_binary_accuracy: 0.4959\n",
            "Epoch 17/25\n",
            "4/4 [==============================] - 2s 695ms/step - loss: 1.4000 - binary_accuracy: 0.5900 - val_loss: 1.5478 - val_binary_accuracy: 0.4959\n",
            "Epoch 18/25\n",
            "4/4 [==============================] - 2s 576ms/step - loss: 1.4400 - binary_accuracy: 0.5700 - val_loss: 1.5478 - val_binary_accuracy: 0.4959\n",
            "Epoch 19/25\n",
            "4/4 [==============================] - 2s 570ms/step - loss: 1.6800 - binary_accuracy: 0.5000 - val_loss: 1.5478 - val_binary_accuracy: 0.4959\n",
            "Epoch 20/25\n",
            "4/4 [==============================] - 2s 590ms/step - loss: 1.6400 - binary_accuracy: 0.5500 - val_loss: 1.5478 - val_binary_accuracy: 0.4959\n",
            "Epoch 21/25\n",
            "4/4 [==============================] - 2s 604ms/step - loss: 1.3600 - binary_accuracy: 0.6000 - val_loss: 1.5478 - val_binary_accuracy: 0.4959\n",
            "Epoch 22/25\n",
            "4/4 [==============================] - 2s 604ms/step - loss: 1.6000 - binary_accuracy: 0.5200 - val_loss: 1.5478 - val_binary_accuracy: 0.4959\n",
            "Epoch 23/25\n",
            "4/4 [==============================] - 2s 621ms/step - loss: 1.0800 - binary_accuracy: 0.6800 - val_loss: 1.5478 - val_binary_accuracy: 0.4959\n",
            "Epoch 24/25\n",
            "4/4 [==============================] - 2s 558ms/step - loss: 1.3600 - binary_accuracy: 0.6300 - val_loss: 1.5478 - val_binary_accuracy: 0.4959\n",
            "Epoch 25/25\n",
            "4/4 [==============================] - 2s 543ms/step - loss: 1.7200 - binary_accuracy: 0.4900 - val_loss: 1.5478 - val_binary_accuracy: 0.4959\n",
            "62/62 [==============================] - 1s 21ms/step - loss: 1.7937 - binary_accuracy: 0.5041\n",
            "Model: \"sequential_91\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " pqc_91 (PQC)                (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9\n",
            "Trainable params: 9\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/25\n",
            "4/4 [==============================] - 4s 1s/step - loss: 1.8800 - binary_accuracy: 0.4500 - val_loss: 1.8730 - val_binary_accuracy: 0.4253\n",
            "Epoch 2/25\n",
            "4/4 [==============================] - 3s 972ms/step - loss: 1.8800 - binary_accuracy: 0.4300 - val_loss: 1.8730 - val_binary_accuracy: 0.4253\n",
            "Epoch 3/25\n",
            "4/4 [==============================] - 3s 918ms/step - loss: 1.8400 - binary_accuracy: 0.4000 - val_loss: 1.8730 - val_binary_accuracy: 0.4253\n",
            "Epoch 4/25\n",
            "4/4 [==============================] - 3s 979ms/step - loss: 2.1600 - binary_accuracy: 0.3600 - val_loss: 1.8730 - val_binary_accuracy: 0.4253\n",
            "Epoch 5/25\n",
            "4/4 [==============================] - 3s 1s/step - loss: 2.0000 - binary_accuracy: 0.4200 - val_loss: 1.8730 - val_binary_accuracy: 0.4253\n",
            "Epoch 6/25\n",
            "4/4 [==============================] - 3s 1s/step - loss: 2.0800 - binary_accuracy: 0.4800 - val_loss: 1.8730 - val_binary_accuracy: 0.4253\n",
            "Epoch 7/25\n",
            "4/4 [==============================] - 3s 1s/step - loss: 1.8400 - binary_accuracy: 0.4400 - val_loss: 1.8730 - val_binary_accuracy: 0.4253\n",
            "Epoch 8/25\n",
            "4/4 [==============================] - 3s 1s/step - loss: 1.8400 - binary_accuracy: 0.4200 - val_loss: 1.8730 - val_binary_accuracy: 0.4253\n",
            "Epoch 9/25\n",
            "4/4 [==============================] - 3s 1s/step - loss: 2.0800 - binary_accuracy: 0.3700 - val_loss: 1.8730 - val_binary_accuracy: 0.4253\n",
            "Epoch 10/25\n",
            "4/4 [==============================] - 3s 1s/step - loss: 2.0400 - binary_accuracy: 0.4000 - val_loss: 1.8730 - val_binary_accuracy: 0.4253\n",
            "Epoch 11/25\n",
            "4/4 [==============================] - 3s 1s/step - loss: 1.9600 - binary_accuracy: 0.4500 - val_loss: 1.8730 - val_binary_accuracy: 0.4253\n",
            "Epoch 12/25\n",
            "4/4 [==============================] - 3s 1s/step - loss: 2.0400 - binary_accuracy: 0.4200 - val_loss: 1.8730 - val_binary_accuracy: 0.4253\n",
            "Epoch 13/25\n",
            "4/4 [==============================] - 3s 1s/step - loss: 1.9200 - binary_accuracy: 0.4100 - val_loss: 1.8730 - val_binary_accuracy: 0.4253\n",
            "Epoch 14/25\n",
            "4/4 [==============================] - 3s 1s/step - loss: 2.2000 - binary_accuracy: 0.3600 - val_loss: 1.8730 - val_binary_accuracy: 0.4253\n",
            "Epoch 15/25\n",
            "4/4 [==============================] - 3s 1s/step - loss: 2.0400 - binary_accuracy: 0.4200 - val_loss: 1.8730 - val_binary_accuracy: 0.4253\n",
            "Epoch 16/25\n",
            "4/4 [==============================] - 3s 1s/step - loss: 1.8800 - binary_accuracy: 0.3900 - val_loss: 1.8730 - val_binary_accuracy: 0.4253\n",
            "Epoch 17/25\n",
            "4/4 [==============================] - 3s 1s/step - loss: 2.0000 - binary_accuracy: 0.4100 - val_loss: 1.8730 - val_binary_accuracy: 0.4253\n",
            "Epoch 18/25\n",
            "4/4 [==============================] - 3s 1s/step - loss: 2.1200 - binary_accuracy: 0.3700 - val_loss: 1.8730 - val_binary_accuracy: 0.4253\n",
            "Epoch 19/25\n",
            "4/4 [==============================] - 3s 1s/step - loss: 1.9200 - binary_accuracy: 0.4600 - val_loss: 1.8730 - val_binary_accuracy: 0.4253\n",
            "Epoch 20/25\n",
            "4/4 [==============================] - 3s 962ms/step - loss: 2.0400 - binary_accuracy: 0.3500 - val_loss: 1.8730 - val_binary_accuracy: 0.4253\n",
            "Epoch 21/25\n",
            "4/4 [==============================] - 3s 971ms/step - loss: 1.8400 - binary_accuracy: 0.4300 - val_loss: 1.8730 - val_binary_accuracy: 0.4253\n",
            "Epoch 22/25\n",
            "4/4 [==============================] - 3s 982ms/step - loss: 2.0400 - binary_accuracy: 0.3700 - val_loss: 1.8730 - val_binary_accuracy: 0.4253\n",
            "Epoch 23/25\n",
            "4/4 [==============================] - 3s 962ms/step - loss: 2.1200 - binary_accuracy: 0.3600 - val_loss: 1.8730 - val_binary_accuracy: 0.4253\n",
            "Epoch 24/25\n",
            "4/4 [==============================] - 3s 1s/step - loss: 2.2400 - binary_accuracy: 0.3800 - val_loss: 1.8730 - val_binary_accuracy: 0.4253\n",
            "Epoch 25/25\n",
            "4/4 [==============================] - 3s 1s/step - loss: 1.8800 - binary_accuracy: 0.4400 - val_loss: 1.8730 - val_binary_accuracy: 0.4253\n",
            "62/62 [==============================] - 3s 45ms/step - loss: 2.1372 - binary_accuracy: 0.4345\n",
            "Model: \"sequential_92\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " pqc_92 (PQC)                (None, 1)                 4         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4\n",
            "Trainable params: 4\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/25\n",
            "4/4 [==============================] - 3s 642ms/step - loss: 0.5338 - binary_accuracy: 0.5300 - val_loss: 0.5755 - val_binary_accuracy: 0.4980\n",
            "Epoch 2/25\n",
            "4/4 [==============================] - 2s 575ms/step - loss: 0.5163 - binary_accuracy: 0.5700 - val_loss: 0.5709 - val_binary_accuracy: 0.4980\n",
            "Epoch 3/25\n",
            "4/4 [==============================] - 2s 546ms/step - loss: 0.5832 - binary_accuracy: 0.5600 - val_loss: 0.5664 - val_binary_accuracy: 0.4980\n",
            "Epoch 4/25\n",
            "4/4 [==============================] - 2s 548ms/step - loss: 0.4241 - binary_accuracy: 0.6300 - val_loss: 0.5621 - val_binary_accuracy: 0.4980\n",
            "Epoch 5/25\n",
            "4/4 [==============================] - 2s 526ms/step - loss: 0.4901 - binary_accuracy: 0.6000 - val_loss: 0.5581 - val_binary_accuracy: 0.4980\n",
            "Epoch 6/25\n",
            "4/4 [==============================] - 2s 539ms/step - loss: 0.5021 - binary_accuracy: 0.5500 - val_loss: 0.5540 - val_binary_accuracy: 0.4980\n",
            "Epoch 7/25\n",
            "4/4 [==============================] - 2s 526ms/step - loss: 0.4564 - binary_accuracy: 0.6300 - val_loss: 0.5500 - val_binary_accuracy: 0.4980\n",
            "Epoch 8/25\n",
            "4/4 [==============================] - 2s 551ms/step - loss: 0.4691 - binary_accuracy: 0.5800 - val_loss: 0.5462 - val_binary_accuracy: 0.4980\n",
            "Epoch 9/25\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 0.4440 - binary_accuracy: 0.5900 - val_loss: 0.5426 - val_binary_accuracy: 0.4980\n",
            "Epoch 10/25\n",
            "4/4 [==============================] - 2s 541ms/step - loss: 0.4307 - binary_accuracy: 0.5600 - val_loss: 0.5390 - val_binary_accuracy: 0.4980\n",
            "Epoch 11/25\n",
            "4/4 [==============================] - 2s 520ms/step - loss: 0.4846 - binary_accuracy: 0.5900 - val_loss: 0.5354 - val_binary_accuracy: 0.4980\n",
            "Epoch 12/25\n",
            "4/4 [==============================] - 2s 530ms/step - loss: 0.4456 - binary_accuracy: 0.6000 - val_loss: 0.5320 - val_binary_accuracy: 0.4980\n",
            "Epoch 13/25\n",
            "4/4 [==============================] - 2s 526ms/step - loss: 0.4032 - binary_accuracy: 0.6000 - val_loss: 0.5287 - val_binary_accuracy: 0.4980\n",
            "Epoch 14/25\n",
            "4/4 [==============================] - 2s 545ms/step - loss: 0.4265 - binary_accuracy: 0.5800 - val_loss: 0.5255 - val_binary_accuracy: 0.4980\n",
            "Epoch 15/25\n",
            "4/4 [==============================] - 2s 557ms/step - loss: 0.5218 - binary_accuracy: 0.5100 - val_loss: 0.5221 - val_binary_accuracy: 0.4980\n",
            "Epoch 16/25\n",
            "4/4 [==============================] - 2s 556ms/step - loss: 0.4143 - binary_accuracy: 0.5800 - val_loss: 0.5188 - val_binary_accuracy: 0.4980\n",
            "Epoch 17/25\n",
            "4/4 [==============================] - 2s 587ms/step - loss: 0.4282 - binary_accuracy: 0.6100 - val_loss: 0.5155 - val_binary_accuracy: 0.4980\n",
            "Epoch 18/25\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 0.4202 - binary_accuracy: 0.6100 - val_loss: 0.5124 - val_binary_accuracy: 0.4980\n",
            "Epoch 19/25\n",
            "4/4 [==============================] - 2s 545ms/step - loss: 0.3890 - binary_accuracy: 0.6100 - val_loss: 0.5095 - val_binary_accuracy: 0.4980\n",
            "Epoch 20/25\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 0.4490 - binary_accuracy: 0.5500 - val_loss: 0.5067 - val_binary_accuracy: 0.4980\n",
            "Epoch 21/25\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 0.4313 - binary_accuracy: 0.5800 - val_loss: 0.5039 - val_binary_accuracy: 0.4980\n",
            "Epoch 22/25\n",
            "4/4 [==============================] - 2s 583ms/step - loss: 0.3928 - binary_accuracy: 0.6600 - val_loss: 0.5013 - val_binary_accuracy: 0.4980\n",
            "Epoch 23/25\n",
            "4/4 [==============================] - 2s 527ms/step - loss: 0.3648 - binary_accuracy: 0.6000 - val_loss: 0.4988 - val_binary_accuracy: 0.4980\n",
            "Epoch 24/25\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 0.3709 - binary_accuracy: 0.6000 - val_loss: 0.4964 - val_binary_accuracy: 0.4980\n",
            "Epoch 25/25\n",
            "4/4 [==============================] - 2s 526ms/step - loss: 0.4291 - binary_accuracy: 0.5600 - val_loss: 0.4941 - val_binary_accuracy: 0.4980\n",
            "62/62 [==============================] - 1s 23ms/step - loss: 0.4919 - binary_accuracy: 0.5071\n",
            "Model: \"sequential_93\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " pqc_93 (PQC)                (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9\n",
            "Trainable params: 9\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/25\n",
            "4/4 [==============================] - 4s 1s/step - loss: 0.4438 - binary_accuracy: 0.4800 - val_loss: 0.5525 - val_binary_accuracy: 0.4253\n",
            "Epoch 2/25\n",
            "4/4 [==============================] - 3s 966ms/step - loss: 0.4495 - binary_accuracy: 0.4700 - val_loss: 0.5510 - val_binary_accuracy: 0.4253\n",
            "Epoch 3/25\n",
            "4/4 [==============================] - 3s 978ms/step - loss: 0.5165 - binary_accuracy: 0.3800 - val_loss: 0.5497 - val_binary_accuracy: 0.4253\n",
            "Epoch 4/25\n",
            "4/4 [==============================] - 3s 982ms/step - loss: 0.4926 - binary_accuracy: 0.4200 - val_loss: 0.5485 - val_binary_accuracy: 0.4253\n",
            "Epoch 5/25\n",
            "4/4 [==============================] - 4s 1s/step - loss: 0.5263 - binary_accuracy: 0.4000 - val_loss: 0.5472 - val_binary_accuracy: 0.4289\n",
            "Epoch 6/25\n",
            "4/4 [==============================] - 3s 946ms/step - loss: 0.5156 - binary_accuracy: 0.4300 - val_loss: 0.5458 - val_binary_accuracy: 0.4294\n",
            "Epoch 7/25\n",
            "4/4 [==============================] - 3s 972ms/step - loss: 0.4966 - binary_accuracy: 0.4200 - val_loss: 0.5445 - val_binary_accuracy: 0.4294\n",
            "Epoch 8/25\n",
            "4/4 [==============================] - 3s 926ms/step - loss: 0.4845 - binary_accuracy: 0.4300 - val_loss: 0.5433 - val_binary_accuracy: 0.4294\n",
            "Epoch 9/25\n",
            "4/4 [==============================] - 3s 965ms/step - loss: 0.4729 - binary_accuracy: 0.4200 - val_loss: 0.5421 - val_binary_accuracy: 0.4294\n",
            "Epoch 10/25\n",
            "4/4 [==============================] - 3s 988ms/step - loss: 0.4603 - binary_accuracy: 0.4600 - val_loss: 0.5409 - val_binary_accuracy: 0.4294\n",
            "Epoch 11/25\n",
            "4/4 [==============================] - 3s 933ms/step - loss: 0.4843 - binary_accuracy: 0.4400 - val_loss: 0.5398 - val_binary_accuracy: 0.4294\n",
            "Epoch 12/25\n",
            "4/4 [==============================] - 3s 941ms/step - loss: 0.4715 - binary_accuracy: 0.4300 - val_loss: 0.5387 - val_binary_accuracy: 0.4289\n",
            "Epoch 13/25\n",
            "4/4 [==============================] - 3s 973ms/step - loss: 0.4980 - binary_accuracy: 0.4400 - val_loss: 0.5376 - val_binary_accuracy: 0.4289\n",
            "Epoch 14/25\n",
            "4/4 [==============================] - 3s 943ms/step - loss: 0.4526 - binary_accuracy: 0.4800 - val_loss: 0.5365 - val_binary_accuracy: 0.4289\n",
            "Epoch 15/25\n",
            "4/4 [==============================] - 3s 954ms/step - loss: 0.4087 - binary_accuracy: 0.4800 - val_loss: 0.5354 - val_binary_accuracy: 0.4289\n",
            "Epoch 16/25\n",
            "4/4 [==============================] - 3s 933ms/step - loss: 0.4983 - binary_accuracy: 0.3900 - val_loss: 0.5345 - val_binary_accuracy: 0.4289\n",
            "Epoch 17/25\n",
            "4/4 [==============================] - 3s 948ms/step - loss: 0.4485 - binary_accuracy: 0.4800 - val_loss: 0.5335 - val_binary_accuracy: 0.4299\n",
            "Epoch 18/25\n",
            "4/4 [==============================] - 3s 961ms/step - loss: 0.5216 - binary_accuracy: 0.5100 - val_loss: 0.5324 - val_binary_accuracy: 0.5589\n",
            "Epoch 19/25\n",
            "4/4 [==============================] - 3s 950ms/step - loss: 0.4935 - binary_accuracy: 0.5700 - val_loss: 0.5315 - val_binary_accuracy: 0.5589\n",
            "Epoch 20/25\n",
            "4/4 [==============================] - 3s 948ms/step - loss: 0.4099 - binary_accuracy: 0.6400 - val_loss: 0.5306 - val_binary_accuracy: 0.5595\n",
            "Epoch 21/25\n",
            "4/4 [==============================] - 3s 964ms/step - loss: 0.5144 - binary_accuracy: 0.5400 - val_loss: 0.5298 - val_binary_accuracy: 0.5595\n",
            "Epoch 22/25\n",
            "4/4 [==============================] - 3s 1s/step - loss: 0.4464 - binary_accuracy: 0.6100 - val_loss: 0.5290 - val_binary_accuracy: 0.5595\n",
            "Epoch 23/25\n",
            "4/4 [==============================] - 3s 1s/step - loss: 0.4619 - binary_accuracy: 0.6000 - val_loss: 0.5282 - val_binary_accuracy: 0.5544\n",
            "Epoch 24/25\n",
            "4/4 [==============================] - 3s 968ms/step - loss: 0.4789 - binary_accuracy: 0.5900 - val_loss: 0.5272 - val_binary_accuracy: 0.5544\n",
            "Epoch 25/25\n",
            "4/4 [==============================] - 3s 980ms/step - loss: 0.4302 - binary_accuracy: 0.6100 - val_loss: 0.5263 - val_binary_accuracy: 0.5544\n",
            "62/62 [==============================] - 3s 43ms/step - loss: 0.5209 - binary_accuracy: 0.5788\n",
            "Model: \"sequential_94\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " pqc_94 (PQC)                (None, 1)                 4         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4\n",
            "Trainable params: 4\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/25\n",
            "4/4 [==============================] - 3s 623ms/step - loss: 0.3901 - binary_accuracy: 0.6000 - val_loss: 0.4952 - val_binary_accuracy: 0.4959\n",
            "Epoch 2/25\n",
            "4/4 [==============================] - 2s 513ms/step - loss: 0.4216 - binary_accuracy: 0.5700 - val_loss: 0.4945 - val_binary_accuracy: 0.4959\n",
            "Epoch 3/25\n",
            "4/4 [==============================] - 2s 517ms/step - loss: 0.3631 - binary_accuracy: 0.6300 - val_loss: 0.4938 - val_binary_accuracy: 0.4959\n",
            "Epoch 4/25\n",
            "4/4 [==============================] - 2s 511ms/step - loss: 0.3508 - binary_accuracy: 0.6400 - val_loss: 0.4931 - val_binary_accuracy: 0.4959\n",
            "Epoch 5/25\n",
            "4/4 [==============================] - 2s 509ms/step - loss: 0.4678 - binary_accuracy: 0.5200 - val_loss: 0.4924 - val_binary_accuracy: 0.4959\n",
            "Epoch 6/25\n",
            "4/4 [==============================] - 2s 517ms/step - loss: 0.4198 - binary_accuracy: 0.5700 - val_loss: 0.4916 - val_binary_accuracy: 0.4959\n",
            "Epoch 7/25\n",
            "4/4 [==============================] - 2s 509ms/step - loss: 0.4613 - binary_accuracy: 0.5300 - val_loss: 0.4909 - val_binary_accuracy: 0.4959\n",
            "Epoch 8/25\n",
            "4/4 [==============================] - 2s 519ms/step - loss: 0.4515 - binary_accuracy: 0.5400 - val_loss: 0.4902 - val_binary_accuracy: 0.4959\n",
            "Epoch 9/25\n",
            "4/4 [==============================] - 2s 506ms/step - loss: 0.3777 - binary_accuracy: 0.6100 - val_loss: 0.4895 - val_binary_accuracy: 0.4959\n",
            "Epoch 10/25\n",
            "4/4 [==============================] - 1s 463ms/step - loss: 0.4159 - binary_accuracy: 0.5700 - val_loss: 0.4887 - val_binary_accuracy: 0.4959\n",
            "Epoch 11/25\n",
            "4/4 [==============================] - 2s 497ms/step - loss: 0.4907 - binary_accuracy: 0.4900 - val_loss: 0.4878 - val_binary_accuracy: 0.4959\n",
            "Epoch 12/25\n",
            "4/4 [==============================] - 1s 480ms/step - loss: 0.3911 - binary_accuracy: 0.5900 - val_loss: 0.4869 - val_binary_accuracy: 0.4959\n",
            "Epoch 13/25\n",
            "4/4 [==============================] - 2s 519ms/step - loss: 0.4199 - binary_accuracy: 0.5600 - val_loss: 0.4860 - val_binary_accuracy: 0.4959\n",
            "Epoch 14/25\n",
            "4/4 [==============================] - 2s 506ms/step - loss: 0.3814 - binary_accuracy: 0.6000 - val_loss: 0.4851 - val_binary_accuracy: 0.4959\n",
            "Epoch 15/25\n",
            "4/4 [==============================] - 1s 485ms/step - loss: 0.4302 - binary_accuracy: 0.5500 - val_loss: 0.4842 - val_binary_accuracy: 0.4959\n",
            "Epoch 16/25\n",
            "4/4 [==============================] - 1s 474ms/step - loss: 0.3425 - binary_accuracy: 0.6400 - val_loss: 0.4833 - val_binary_accuracy: 0.4959\n",
            "Epoch 17/25\n",
            "4/4 [==============================] - 2s 504ms/step - loss: 0.3979 - binary_accuracy: 0.5800 - val_loss: 0.4824 - val_binary_accuracy: 0.4959\n",
            "Epoch 18/25\n",
            "4/4 [==============================] - 1s 469ms/step - loss: 0.4309 - binary_accuracy: 0.5400 - val_loss: 0.4814 - val_binary_accuracy: 0.4959\n",
            "Epoch 19/25\n",
            "4/4 [==============================] - 2s 499ms/step - loss: 0.4694 - binary_accuracy: 0.5100 - val_loss: 0.4805 - val_binary_accuracy: 0.4959\n",
            "Epoch 20/25\n",
            "4/4 [==============================] - 2s 505ms/step - loss: 0.4637 - binary_accuracy: 0.5100 - val_loss: 0.4795 - val_binary_accuracy: 0.4959\n",
            "Epoch 21/25\n",
            "4/4 [==============================] - 2s 734ms/step - loss: 0.3691 - binary_accuracy: 0.6100 - val_loss: 0.4785 - val_binary_accuracy: 0.4959\n",
            "Epoch 22/25\n",
            "4/4 [==============================] - 2s 503ms/step - loss: 0.3954 - binary_accuracy: 0.5900 - val_loss: 0.4776 - val_binary_accuracy: 0.4959\n",
            "Epoch 23/25\n",
            "4/4 [==============================] - 2s 510ms/step - loss: 0.3507 - binary_accuracy: 0.6200 - val_loss: 0.4766 - val_binary_accuracy: 0.4959\n",
            "Epoch 24/25\n",
            "4/4 [==============================] - 1s 478ms/step - loss: 0.3918 - binary_accuracy: 0.5800 - val_loss: 0.4757 - val_binary_accuracy: 0.4959\n",
            "Epoch 25/25\n",
            "4/4 [==============================] - 1s 466ms/step - loss: 0.4561 - binary_accuracy: 0.5200 - val_loss: 0.4746 - val_binary_accuracy: 0.4959\n",
            "62/62 [==============================] - 1s 19ms/step - loss: 0.4607 - binary_accuracy: 0.5041\n",
            "Model: \"sequential_95\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " pqc_95 (PQC)                (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9\n",
            "Trainable params: 9\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/25\n",
            "4/4 [==============================] - 4s 930ms/step - loss: 0.7152 - binary_accuracy: 0.3900 - val_loss: 0.6742 - val_binary_accuracy: 0.4253\n",
            "Epoch 2/25\n",
            "4/4 [==============================] - 3s 872ms/step - loss: 0.6782 - binary_accuracy: 0.4300 - val_loss: 0.6698 - val_binary_accuracy: 0.4253\n",
            "Epoch 3/25\n",
            "4/4 [==============================] - 3s 890ms/step - loss: 0.6114 - binary_accuracy: 0.4900 - val_loss: 0.6653 - val_binary_accuracy: 0.4253\n",
            "Epoch 4/25\n",
            "4/4 [==============================] - 3s 978ms/step - loss: 0.7157 - binary_accuracy: 0.3900 - val_loss: 0.6610 - val_binary_accuracy: 0.4253\n",
            "Epoch 5/25\n",
            "4/4 [==============================] - 3s 932ms/step - loss: 0.6885 - binary_accuracy: 0.4000 - val_loss: 0.6568 - val_binary_accuracy: 0.4253\n",
            "Epoch 6/25\n",
            "4/4 [==============================] - 3s 952ms/step - loss: 0.6744 - binary_accuracy: 0.4000 - val_loss: 0.6530 - val_binary_accuracy: 0.4253\n",
            "Epoch 7/25\n",
            "4/4 [==============================] - 3s 907ms/step - loss: 0.5672 - binary_accuracy: 0.5100 - val_loss: 0.6494 - val_binary_accuracy: 0.4253\n",
            "Epoch 8/25\n",
            "4/4 [==============================] - 3s 934ms/step - loss: 0.6708 - binary_accuracy: 0.3900 - val_loss: 0.6460 - val_binary_accuracy: 0.4253\n",
            "Epoch 9/25\n",
            "4/4 [==============================] - 3s 927ms/step - loss: 0.7130 - binary_accuracy: 0.3600 - val_loss: 0.6427 - val_binary_accuracy: 0.4253\n",
            "Epoch 10/25\n",
            "4/4 [==============================] - 3s 944ms/step - loss: 0.6428 - binary_accuracy: 0.4400 - val_loss: 0.6393 - val_binary_accuracy: 0.4253\n",
            "Epoch 11/25\n",
            "4/4 [==============================] - 3s 944ms/step - loss: 0.6468 - binary_accuracy: 0.4200 - val_loss: 0.6361 - val_binary_accuracy: 0.4253\n",
            "Epoch 12/25\n",
            "4/4 [==============================] - 3s 886ms/step - loss: 0.6175 - binary_accuracy: 0.4400 - val_loss: 0.6331 - val_binary_accuracy: 0.4253\n",
            "Epoch 13/25\n",
            "4/4 [==============================] - 3s 915ms/step - loss: 0.6588 - binary_accuracy: 0.4000 - val_loss: 0.6303 - val_binary_accuracy: 0.4253\n",
            "Epoch 14/25\n",
            "4/4 [==============================] - 3s 895ms/step - loss: 0.7344 - binary_accuracy: 0.3300 - val_loss: 0.6274 - val_binary_accuracy: 0.4253\n",
            "Epoch 15/25\n",
            "4/4 [==============================] - 3s 889ms/step - loss: 0.6602 - binary_accuracy: 0.3900 - val_loss: 0.6248 - val_binary_accuracy: 0.4253\n",
            "Epoch 16/25\n",
            "4/4 [==============================] - 3s 896ms/step - loss: 0.7165 - binary_accuracy: 0.3400 - val_loss: 0.6222 - val_binary_accuracy: 0.4253\n",
            "Epoch 17/25\n",
            "4/4 [==============================] - 3s 938ms/step - loss: 0.6654 - binary_accuracy: 0.3800 - val_loss: 0.6197 - val_binary_accuracy: 0.4253\n",
            "Epoch 18/25\n",
            "4/4 [==============================] - 3s 858ms/step - loss: 0.6279 - binary_accuracy: 0.4200 - val_loss: 0.6174 - val_binary_accuracy: 0.4253\n",
            "Epoch 19/25\n",
            "4/4 [==============================] - 3s 927ms/step - loss: 0.7344 - binary_accuracy: 0.3200 - val_loss: 0.6150 - val_binary_accuracy: 0.4253\n",
            "Epoch 20/25\n",
            "4/4 [==============================] - 3s 1s/step - loss: 0.6245 - binary_accuracy: 0.4200 - val_loss: 0.6127 - val_binary_accuracy: 0.4253\n",
            "Epoch 21/25\n",
            "4/4 [==============================] - 4s 1s/step - loss: 0.4946 - binary_accuracy: 0.5400 - val_loss: 0.6107 - val_binary_accuracy: 0.4253\n",
            "Epoch 22/25\n",
            "4/4 [==============================] - 3s 932ms/step - loss: 0.6726 - binary_accuracy: 0.3700 - val_loss: 0.6086 - val_binary_accuracy: 0.4253\n",
            "Epoch 23/25\n",
            "4/4 [==============================] - 3s 956ms/step - loss: 0.6409 - binary_accuracy: 0.3900 - val_loss: 0.6066 - val_binary_accuracy: 0.4253\n",
            "Epoch 24/25\n",
            "4/4 [==============================] - 3s 905ms/step - loss: 0.5597 - binary_accuracy: 0.4700 - val_loss: 0.6048 - val_binary_accuracy: 0.4253\n",
            "Epoch 25/25\n",
            "4/4 [==============================] - 3s 965ms/step - loss: 0.6708 - binary_accuracy: 0.3600 - val_loss: 0.6030 - val_binary_accuracy: 0.4253\n",
            "62/62 [==============================] - 2s 40ms/step - loss: 0.5976 - binary_accuracy: 0.4345\n",
            "Model: \"sequential_96\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " pqc_96 (PQC)                (None, 1)                 4         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4\n",
            "Trainable params: 4\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/25\n",
            "4/4 [==============================] - 2s 579ms/step - loss: 0.7319 - binary_accuracy: 0.5700 - val_loss: 0.8198 - val_binary_accuracy: 0.4959\n",
            "Epoch 2/25\n",
            "4/4 [==============================] - 2s 546ms/step - loss: 0.6985 - binary_accuracy: 0.6300 - val_loss: 0.7854 - val_binary_accuracy: 0.4959\n",
            "Epoch 3/25\n",
            "4/4 [==============================] - 2s 523ms/step - loss: 0.6570 - binary_accuracy: 0.5900 - val_loss: 0.7525 - val_binary_accuracy: 0.4959\n",
            "Epoch 4/25\n",
            "4/4 [==============================] - 2s 538ms/step - loss: 0.6755 - binary_accuracy: 0.5500 - val_loss: 0.7212 - val_binary_accuracy: 0.4959\n",
            "Epoch 5/25\n",
            "4/4 [==============================] - 2s 506ms/step - loss: 0.7733 - binary_accuracy: 0.5200 - val_loss: 0.6897 - val_binary_accuracy: 0.4959\n",
            "Epoch 6/25\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 0.5489 - binary_accuracy: 0.6600 - val_loss: 0.6601 - val_binary_accuracy: 0.4959\n",
            "Epoch 7/25\n",
            "4/4 [==============================] - 2s 511ms/step - loss: 0.5835 - binary_accuracy: 0.6000 - val_loss: 0.6331 - val_binary_accuracy: 0.4959\n",
            "Epoch 8/25\n",
            "4/4 [==============================] - 2s 516ms/step - loss: 0.5014 - binary_accuracy: 0.5900 - val_loss: 0.6078 - val_binary_accuracy: 0.4959\n",
            "Epoch 9/25\n",
            "4/4 [==============================] - 2s 536ms/step - loss: 0.4825 - binary_accuracy: 0.6300 - val_loss: 0.5840 - val_binary_accuracy: 0.4959\n",
            "Epoch 10/25\n",
            "4/4 [==============================] - 1s 488ms/step - loss: 0.5142 - binary_accuracy: 0.5600 - val_loss: 0.5617 - val_binary_accuracy: 0.4959\n",
            "Epoch 11/25\n",
            "4/4 [==============================] - 2s 531ms/step - loss: 0.4794 - binary_accuracy: 0.5700 - val_loss: 0.5412 - val_binary_accuracy: 0.4959\n",
            "Epoch 12/25\n",
            "4/4 [==============================] - 2s 521ms/step - loss: 0.4138 - binary_accuracy: 0.6200 - val_loss: 0.5231 - val_binary_accuracy: 0.4959\n",
            "Epoch 13/25\n",
            "4/4 [==============================] - 2s 501ms/step - loss: 0.3853 - binary_accuracy: 0.6100 - val_loss: 0.5073 - val_binary_accuracy: 0.4959\n",
            "Epoch 14/25\n",
            "4/4 [==============================] - 2s 520ms/step - loss: 0.4111 - binary_accuracy: 0.5900 - val_loss: 0.4932 - val_binary_accuracy: 0.4959\n",
            "Epoch 15/25\n",
            "4/4 [==============================] - 1s 488ms/step - loss: 0.4627 - binary_accuracy: 0.5100 - val_loss: 0.4805 - val_binary_accuracy: 0.4959\n",
            "Epoch 16/25\n",
            "4/4 [==============================] - 2s 548ms/step - loss: 0.4029 - binary_accuracy: 0.5900 - val_loss: 0.4687 - val_binary_accuracy: 0.4959\n",
            "Epoch 17/25\n",
            "4/4 [==============================] - 2s 497ms/step - loss: 0.3913 - binary_accuracy: 0.5800 - val_loss: 0.4579 - val_binary_accuracy: 0.6270\n",
            "Epoch 18/25\n",
            "4/4 [==============================] - 2s 506ms/step - loss: 0.4197 - binary_accuracy: 0.6600 - val_loss: 0.4482 - val_binary_accuracy: 0.6311\n",
            "Epoch 19/25\n",
            "4/4 [==============================] - 2s 508ms/step - loss: 0.3597 - binary_accuracy: 0.7100 - val_loss: 0.4388 - val_binary_accuracy: 0.6311\n",
            "Epoch 20/25\n",
            "4/4 [==============================] - 2s 504ms/step - loss: 0.3741 - binary_accuracy: 0.6600 - val_loss: 0.4304 - val_binary_accuracy: 0.6311\n",
            "Epoch 21/25\n",
            "4/4 [==============================] - 2s 624ms/step - loss: 0.3538 - binary_accuracy: 0.6900 - val_loss: 0.4232 - val_binary_accuracy: 0.6311\n",
            "Epoch 22/25\n",
            "4/4 [==============================] - 1s 398ms/step - loss: 0.3562 - binary_accuracy: 0.6700 - val_loss: 0.4166 - val_binary_accuracy: 0.6311\n",
            "Epoch 23/25\n",
            "4/4 [==============================] - 1s 332ms/step - loss: 0.3088 - binary_accuracy: 0.7200 - val_loss: 0.4110 - val_binary_accuracy: 0.6311\n",
            "Epoch 24/25\n",
            "4/4 [==============================] - 1s 324ms/step - loss: 0.2986 - binary_accuracy: 0.7100 - val_loss: 0.4058 - val_binary_accuracy: 0.6311\n",
            "Epoch 25/25\n",
            "4/4 [==============================] - 1s 329ms/step - loss: 0.3155 - binary_accuracy: 0.6900 - val_loss: 0.4015 - val_binary_accuracy: 0.6311\n",
            "62/62 [==============================] - 1s 12ms/step - loss: 0.3759 - binary_accuracy: 0.6667\n",
            "Model: \"sequential_97\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " pqc_97 (PQC)                (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9\n",
            "Trainable params: 9\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/25\n",
            "4/4 [==============================] - 2s 594ms/step - loss: 0.7594 - binary_accuracy: 0.6100 - val_loss: 0.7676 - val_binary_accuracy: 0.4914\n",
            "Epoch 2/25\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 0.8530 - binary_accuracy: 0.5800 - val_loss: 0.7544 - val_binary_accuracy: 0.5351\n",
            "Epoch 3/25\n",
            "4/4 [==============================] - 2s 573ms/step - loss: 0.7310 - binary_accuracy: 0.6000 - val_loss: 0.7417 - val_binary_accuracy: 0.5340\n",
            "Epoch 4/25\n",
            "4/4 [==============================] - 2s 560ms/step - loss: 0.7032 - binary_accuracy: 0.5900 - val_loss: 0.7300 - val_binary_accuracy: 0.5340\n",
            "Epoch 5/25\n",
            "4/4 [==============================] - 2s 584ms/step - loss: 0.7015 - binary_accuracy: 0.5400 - val_loss: 0.7190 - val_binary_accuracy: 0.5579\n",
            "Epoch 6/25\n",
            "4/4 [==============================] - 2s 561ms/step - loss: 0.7879 - binary_accuracy: 0.5800 - val_loss: 0.7071 - val_binary_accuracy: 0.5478\n",
            "Epoch 7/25\n",
            "4/4 [==============================] - 2s 586ms/step - loss: 0.8648 - binary_accuracy: 0.4800 - val_loss: 0.6953 - val_binary_accuracy: 0.5279\n",
            "Epoch 8/25\n",
            "4/4 [==============================] - 2s 587ms/step - loss: 0.6154 - binary_accuracy: 0.6000 - val_loss: 0.6856 - val_binary_accuracy: 0.5279\n",
            "Epoch 9/25\n",
            "4/4 [==============================] - 2s 583ms/step - loss: 0.7085 - binary_accuracy: 0.5600 - val_loss: 0.6782 - val_binary_accuracy: 0.5407\n",
            "Epoch 10/25\n",
            "4/4 [==============================] - 2s 575ms/step - loss: 0.7187 - binary_accuracy: 0.5400 - val_loss: 0.6726 - val_binary_accuracy: 0.5356\n",
            "Epoch 11/25\n",
            "4/4 [==============================] - 2s 608ms/step - loss: 0.7586 - binary_accuracy: 0.4900 - val_loss: 0.6676 - val_binary_accuracy: 0.5310\n",
            "Epoch 12/25\n",
            "4/4 [==============================] - 2s 586ms/step - loss: 0.6291 - binary_accuracy: 0.6300 - val_loss: 0.6647 - val_binary_accuracy: 0.5259\n",
            "Epoch 13/25\n",
            "4/4 [==============================] - 2s 575ms/step - loss: 0.6341 - binary_accuracy: 0.5300 - val_loss: 0.6631 - val_binary_accuracy: 0.5259\n",
            "Epoch 14/25\n",
            "4/4 [==============================] - 2s 575ms/step - loss: 0.6495 - binary_accuracy: 0.5500 - val_loss: 0.6628 - val_binary_accuracy: 0.5259\n",
            "Epoch 15/25\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 0.6421 - binary_accuracy: 0.5400 - val_loss: 0.6631 - val_binary_accuracy: 0.5259\n",
            "Epoch 16/25\n",
            "4/4 [==============================] - 2s 571ms/step - loss: 0.6312 - binary_accuracy: 0.5800 - val_loss: 0.6637 - val_binary_accuracy: 0.5254\n",
            "Epoch 17/25\n",
            "4/4 [==============================] - 2s 589ms/step - loss: 0.6636 - binary_accuracy: 0.5300 - val_loss: 0.6647 - val_binary_accuracy: 0.5254\n",
            "Epoch 18/25\n",
            "4/4 [==============================] - 2s 588ms/step - loss: 0.6392 - binary_accuracy: 0.5900 - val_loss: 0.6659 - val_binary_accuracy: 0.5254\n",
            "Epoch 19/25\n",
            "4/4 [==============================] - 3s 881ms/step - loss: 0.6184 - binary_accuracy: 0.5700 - val_loss: 0.6666 - val_binary_accuracy: 0.5254\n",
            "Epoch 20/25\n",
            "4/4 [==============================] - 3s 1s/step - loss: 0.5646 - binary_accuracy: 0.6000 - val_loss: 0.6671 - val_binary_accuracy: 0.5254\n",
            "Epoch 21/25\n",
            "4/4 [==============================] - 2s 589ms/step - loss: 0.6706 - binary_accuracy: 0.4900 - val_loss: 0.6678 - val_binary_accuracy: 0.5254\n",
            "Epoch 22/25\n",
            "4/4 [==============================] - 2s 590ms/step - loss: 0.6813 - binary_accuracy: 0.5400 - val_loss: 0.6684 - val_binary_accuracy: 0.5254\n",
            "Epoch 23/25\n",
            "4/4 [==============================] - 2s 581ms/step - loss: 0.6762 - binary_accuracy: 0.5300 - val_loss: 0.6695 - val_binary_accuracy: 0.5254\n",
            "Epoch 24/25\n",
            "4/4 [==============================] - 2s 598ms/step - loss: 0.5865 - binary_accuracy: 0.5800 - val_loss: 0.6705 - val_binary_accuracy: 0.5254\n",
            "Epoch 25/25\n",
            "4/4 [==============================] - 2s 590ms/step - loss: 0.6359 - binary_accuracy: 0.5700 - val_loss: 0.6715 - val_binary_accuracy: 0.5254\n",
            "62/62 [==============================] - 2s 25ms/step - loss: 0.6809 - binary_accuracy: 0.5396\n",
            "Model: \"sequential_98\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " pqc_98 (PQC)                (None, 1)                 4         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4\n",
            "Trainable params: 4\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/25\n",
            "4/4 [==============================] - 2s 401ms/step - loss: 0.4367 - binary_accuracy: 0.5600 - val_loss: 0.4998 - val_binary_accuracy: 0.4959\n",
            "Epoch 2/25\n",
            "4/4 [==============================] - 2s 543ms/step - loss: 0.4141 - binary_accuracy: 0.5800 - val_loss: 0.4978 - val_binary_accuracy: 0.4959\n",
            "Epoch 3/25\n",
            "4/4 [==============================] - 1s 324ms/step - loss: 0.4130 - binary_accuracy: 0.5700 - val_loss: 0.4962 - val_binary_accuracy: 0.4959\n",
            "Epoch 4/25\n",
            "4/4 [==============================] - 1s 322ms/step - loss: 0.3963 - binary_accuracy: 0.5900 - val_loss: 0.4947 - val_binary_accuracy: 0.4959\n",
            "Epoch 5/25\n",
            "4/4 [==============================] - 1s 334ms/step - loss: 0.3803 - binary_accuracy: 0.6100 - val_loss: 0.4934 - val_binary_accuracy: 0.4959\n",
            "Epoch 6/25\n",
            "4/4 [==============================] - 1s 337ms/step - loss: 0.4465 - binary_accuracy: 0.5400 - val_loss: 0.4923 - val_binary_accuracy: 0.4959\n",
            "Epoch 7/25\n",
            "4/4 [==============================] - 1s 344ms/step - loss: 0.3799 - binary_accuracy: 0.6000 - val_loss: 0.4912 - val_binary_accuracy: 0.4959\n",
            "Epoch 8/25\n",
            "4/4 [==============================] - 2s 576ms/step - loss: 0.4053 - binary_accuracy: 0.5800 - val_loss: 0.4903 - val_binary_accuracy: 0.4959\n",
            "Epoch 9/25\n",
            "4/4 [==============================] - 2s 722ms/step - loss: 0.3658 - binary_accuracy: 0.6200 - val_loss: 0.4894 - val_binary_accuracy: 0.4959\n",
            "Epoch 10/25\n",
            "4/4 [==============================] - 1s 336ms/step - loss: 0.3622 - binary_accuracy: 0.6200 - val_loss: 0.4885 - val_binary_accuracy: 0.4959\n",
            "Epoch 11/25\n",
            "4/4 [==============================] - 1s 336ms/step - loss: 0.3896 - binary_accuracy: 0.6000 - val_loss: 0.4877 - val_binary_accuracy: 0.4959\n",
            "Epoch 12/25\n",
            "4/4 [==============================] - 1s 342ms/step - loss: 0.3761 - binary_accuracy: 0.6100 - val_loss: 0.4869 - val_binary_accuracy: 0.4959\n",
            "Epoch 13/25\n",
            "4/4 [==============================] - 2s 549ms/step - loss: 0.3866 - binary_accuracy: 0.5900 - val_loss: 0.4861 - val_binary_accuracy: 0.4959\n",
            "Epoch 14/25\n",
            "4/4 [==============================] - 1s 348ms/step - loss: 0.3485 - binary_accuracy: 0.6400 - val_loss: 0.4853 - val_binary_accuracy: 0.4959\n",
            "Epoch 15/25\n",
            "4/4 [==============================] - 1s 347ms/step - loss: 0.3796 - binary_accuracy: 0.6000 - val_loss: 0.4845 - val_binary_accuracy: 0.4959\n",
            "Epoch 16/25\n",
            "4/4 [==============================] - 1s 341ms/step - loss: 0.4348 - binary_accuracy: 0.5400 - val_loss: 0.4837 - val_binary_accuracy: 0.4959\n",
            "Epoch 17/25\n",
            "4/4 [==============================] - 1s 337ms/step - loss: 0.4385 - binary_accuracy: 0.5300 - val_loss: 0.4827 - val_binary_accuracy: 0.4959\n",
            "Epoch 18/25\n",
            "4/4 [==============================] - 2s 550ms/step - loss: 0.4431 - binary_accuracy: 0.5300 - val_loss: 0.4818 - val_binary_accuracy: 0.4959\n",
            "Epoch 19/25\n",
            "4/4 [==============================] - 1s 334ms/step - loss: 0.3426 - binary_accuracy: 0.6400 - val_loss: 0.4809 - val_binary_accuracy: 0.4959\n",
            "Epoch 20/25\n",
            "4/4 [==============================] - 1s 333ms/step - loss: 0.4330 - binary_accuracy: 0.5400 - val_loss: 0.4800 - val_binary_accuracy: 0.4959\n",
            "Epoch 21/25\n",
            "4/4 [==============================] - 1s 338ms/step - loss: 0.4533 - binary_accuracy: 0.5100 - val_loss: 0.4790 - val_binary_accuracy: 0.4959\n",
            "Epoch 22/25\n",
            "4/4 [==============================] - 1s 326ms/step - loss: 0.4017 - binary_accuracy: 0.5700 - val_loss: 0.4781 - val_binary_accuracy: 0.4959\n",
            "Epoch 23/25\n",
            "4/4 [==============================] - 1s 332ms/step - loss: 0.3728 - binary_accuracy: 0.6000 - val_loss: 0.4772 - val_binary_accuracy: 0.4959\n",
            "Epoch 24/25\n",
            "4/4 [==============================] - 1s 324ms/step - loss: 0.3759 - binary_accuracy: 0.6000 - val_loss: 0.4763 - val_binary_accuracy: 0.4959\n",
            "Epoch 25/25\n",
            "4/4 [==============================] - 1s 328ms/step - loss: 0.3225 - binary_accuracy: 0.6500 - val_loss: 0.4753 - val_binary_accuracy: 0.4959\n",
            "62/62 [==============================] - 1s 12ms/step - loss: 0.4616 - binary_accuracy: 0.5041\n",
            "Model: \"sequential_99\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " pqc_99 (PQC)                (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9\n",
            "Trainable params: 9\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/25\n",
            "4/4 [==============================] - 2s 623ms/step - loss: 0.5302 - binary_accuracy: 0.4700 - val_loss: 0.5748 - val_binary_accuracy: 0.4253\n",
            "Epoch 2/25\n",
            "4/4 [==============================] - 2s 577ms/step - loss: 0.6901 - binary_accuracy: 0.3100 - val_loss: 0.5748 - val_binary_accuracy: 0.4253\n",
            "Epoch 3/25\n",
            "4/4 [==============================] - 2s 583ms/step - loss: 0.5301 - binary_accuracy: 0.4700 - val_loss: 0.5748 - val_binary_accuracy: 0.4253\n",
            "Epoch 4/25\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 0.5901 - binary_accuracy: 0.4100 - val_loss: 0.5747 - val_binary_accuracy: 0.4253\n",
            "Epoch 5/25\n",
            "4/4 [==============================] - 3s 999ms/step - loss: 0.6800 - binary_accuracy: 0.3200 - val_loss: 0.5747 - val_binary_accuracy: 0.4253\n",
            "Epoch 6/25\n",
            "4/4 [==============================] - 2s 606ms/step - loss: 0.5600 - binary_accuracy: 0.4400 - val_loss: 0.5747 - val_binary_accuracy: 0.4253\n",
            "Epoch 7/25\n",
            "4/4 [==============================] - 2s 575ms/step - loss: 0.5900 - binary_accuracy: 0.4100 - val_loss: 0.5747 - val_binary_accuracy: 0.4253\n",
            "Epoch 8/25\n",
            "4/4 [==============================] - 2s 578ms/step - loss: 0.6100 - binary_accuracy: 0.3900 - val_loss: 0.5747 - val_binary_accuracy: 0.4253\n",
            "Epoch 9/25\n",
            "4/4 [==============================] - 2s 584ms/step - loss: 0.6200 - binary_accuracy: 0.3800 - val_loss: 0.5747 - val_binary_accuracy: 0.4253\n",
            "Epoch 10/25\n",
            "4/4 [==============================] - 2s 588ms/step - loss: 0.5100 - binary_accuracy: 0.4900 - val_loss: 0.5747 - val_binary_accuracy: 0.4253\n",
            "Epoch 11/25\n",
            "4/4 [==============================] - 2s 591ms/step - loss: 0.6100 - binary_accuracy: 0.3900 - val_loss: 0.5747 - val_binary_accuracy: 0.4253\n",
            "Epoch 12/25\n",
            "4/4 [==============================] - 2s 585ms/step - loss: 0.5400 - binary_accuracy: 0.4600 - val_loss: 0.5747 - val_binary_accuracy: 0.4253\n",
            "Epoch 13/25\n",
            "4/4 [==============================] - 2s 580ms/step - loss: 0.6099 - binary_accuracy: 0.3900 - val_loss: 0.5747 - val_binary_accuracy: 0.4253\n",
            "Epoch 14/25\n",
            "4/4 [==============================] - 2s 582ms/step - loss: 0.6099 - binary_accuracy: 0.3900 - val_loss: 0.5747 - val_binary_accuracy: 0.4253\n",
            "Epoch 15/25\n",
            "4/4 [==============================] - 2s 577ms/step - loss: 0.6100 - binary_accuracy: 0.3900 - val_loss: 0.5747 - val_binary_accuracy: 0.4253\n",
            "Epoch 16/25\n",
            "4/4 [==============================] - 2s 575ms/step - loss: 0.6600 - binary_accuracy: 0.3400 - val_loss: 0.5747 - val_binary_accuracy: 0.4253\n",
            "Epoch 17/25\n",
            "4/4 [==============================] - 2s 599ms/step - loss: 0.5699 - binary_accuracy: 0.4300 - val_loss: 0.5747 - val_binary_accuracy: 0.4253\n",
            "Epoch 18/25\n",
            "4/4 [==============================] - 2s 587ms/step - loss: 0.6699 - binary_accuracy: 0.3300 - val_loss: 0.5746 - val_binary_accuracy: 0.4253\n",
            "Epoch 19/25\n",
            "4/4 [==============================] - 2s 581ms/step - loss: 0.6399 - binary_accuracy: 0.3600 - val_loss: 0.5746 - val_binary_accuracy: 0.4253\n",
            "Epoch 20/25\n",
            "4/4 [==============================] - 2s 571ms/step - loss: 0.5898 - binary_accuracy: 0.4100 - val_loss: 0.5746 - val_binary_accuracy: 0.4253\n",
            "Epoch 21/25\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 0.5397 - binary_accuracy: 0.4600 - val_loss: 0.5746 - val_binary_accuracy: 0.4253\n",
            "Epoch 22/25\n",
            "4/4 [==============================] - 2s 559ms/step - loss: 0.6996 - binary_accuracy: 0.3000 - val_loss: 0.5746 - val_binary_accuracy: 0.4253\n",
            "Epoch 23/25\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 0.5297 - binary_accuracy: 0.4700 - val_loss: 0.5745 - val_binary_accuracy: 0.4253\n",
            "Epoch 24/25\n",
            "4/4 [==============================] - 2s 551ms/step - loss: 0.5395 - binary_accuracy: 0.4600 - val_loss: 0.5745 - val_binary_accuracy: 0.4253\n",
            "Epoch 25/25\n",
            "4/4 [==============================] - 2s 575ms/step - loss: 0.6197 - binary_accuracy: 0.3800 - val_loss: 0.5744 - val_binary_accuracy: 0.4253\n",
            "62/62 [==============================] - 2s 33ms/step - loss: 0.5653 - binary_accuracy: 0.4345\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "experiment = 7\n",
        "\n",
        "print(experiment_log[experiment]['history'])\n",
        "print(experiment_log[experiment]['gates'])\n",
        "\n",
        "pyplot.plot(experiment_log[experiment]['history'].history['loss'])\n",
        "pyplot.plot(experiment_log[experiment]['history'].history['val_loss'])\n",
        "\n",
        "SVGCircuit(experiment_log[experiment]['circuit'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "dNW57F88Gg0T",
        "outputId": "7e8a64fc-e299-4704-cf47-4b144090e537"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.font_manager:findfont: Font family ['Arial'] not found. Falling back to DejaVu Sans.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<keras.callbacks.History object at 0x7fa606231150>\n",
            "[cirq.CZ, cirq.ZZ]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<cirq.contrib.svg.svg.SVGCircuit at 0x7fa605ac2e10>"
            ],
            "image/svg+xml": "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"1138.2546875\" height=\"250.0\"><line x1=\"39.810625\" x2=\"1108.2546875\" y1=\"25.0\" y2=\"25.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"39.810625\" x2=\"1108.2546875\" y1=\"75.0\" y2=\"75.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"39.810625\" x2=\"1108.2546875\" y1=\"125.0\" y2=\"125.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"39.810625\" x2=\"1108.2546875\" y1=\"175.0\" y2=\"175.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"39.810625\" x2=\"1108.2546875\" y1=\"225.0\" y2=\"225.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"250.6671484375\" x2=\"250.6671484375\" y1=\"25.0\" y2=\"75.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"352.75894531250003\" x2=\"352.75894531250003\" y1=\"25.0\" y2=\"125.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"454.85074218750003\" x2=\"454.85074218750003\" y1=\"25.0\" y2=\"175.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"556.9425390625\" x2=\"556.9425390625\" y1=\"25.0\" y2=\"225.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"661.77171875\" x2=\"661.77171875\" y1=\"25.0\" y2=\"75.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"769.33828125\" x2=\"769.33828125\" y1=\"25.0\" y2=\"125.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"876.90484375\" x2=\"876.90484375\" y1=\"25.0\" y2=\"175.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"984.4714062500001\" x2=\"984.4714062500001\" y1=\"25.0\" y2=\"225.0\" stroke=\"black\" stroke-width=\"3\" /><rect x=\"10.0\" y=\"5.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(-1, -1): </text><rect x=\"10.0\" y=\"55.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, 0): </text><rect x=\"10.0\" y=\"105.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, 1): </text><rect x=\"10.0\" y=\"155.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(1, 0): </text><rect x=\"10.0\" y=\"205.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"225.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(1, 1): </text><rect x=\"89.62125\" y=\"5.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"109.62125\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><rect x=\"149.62125\" y=\"5.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"169.62125\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">H</text><rect x=\"209.62125\" y=\"55.0\" width=\"82.09179687500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"250.6671484375\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">@^(zz1-0)</text><circle cx=\"250.6671484375\" cy=\"25.0\" r=\"10.0\" /><rect x=\"311.71304687500003\" y=\"105.0\" width=\"82.09179687500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"352.75894531250003\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">@^(zz1-1)</text><circle cx=\"352.75894531250003\" cy=\"25.0\" r=\"10.0\" /><rect x=\"413.80484375000003\" y=\"155.0\" width=\"82.09179687500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"454.85074218750003\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">@^(zz1-2)</text><circle cx=\"454.85074218750003\" cy=\"25.0\" r=\"10.0\" /><rect x=\"515.896640625\" y=\"205.0\" width=\"82.09179687500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"556.9425390625\" y=\"225.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">@^(zz1-3)</text><circle cx=\"556.9425390625\" cy=\"25.0\" r=\"10.0\" /><rect x=\"617.9884375\" y=\"55.0\" width=\"87.56656250000002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"661.77171875\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ^(zz1-0)</text><rect x=\"617.9884375\" y=\"5.0\" width=\"87.56656250000002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"661.77171875\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ</text><rect x=\"725.5550000000001\" y=\"105.0\" width=\"87.56656250000002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"769.33828125\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ^(zz1-1)</text><rect x=\"725.5550000000001\" y=\"5.0\" width=\"87.56656250000002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"769.33828125\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ</text><rect x=\"833.1215625000001\" y=\"155.0\" width=\"87.56656250000002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"876.90484375\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ^(zz1-2)</text><rect x=\"833.1215625000001\" y=\"5.0\" width=\"87.56656250000002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"876.90484375\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ</text><rect x=\"940.6881250000001\" y=\"205.0\" width=\"87.56656250000002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"984.4714062500001\" y=\"225.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ^(zz1-3)</text><rect x=\"940.6881250000001\" y=\"5.0\" width=\"87.56656250000002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"984.4714062500001\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ</text><rect x=\"1048.2546875\" y=\"5.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1068.2546875\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">H</text></svg>"
          },
          "metadata": {},
          "execution_count": 121
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "CB3Cy5ZXGg-X"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "w2gvtX_YGhJU"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "O7TQaBshMhcJ"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DlxrKE3qMhoQ"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hCi_lvWpMhz1"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZRmxzLEALiNr"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "IMdrzvqvGQo4"
      },
      "execution_count": 115,
      "outputs": []
    }
  ]
}